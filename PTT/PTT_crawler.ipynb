{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:17<00:00, 17.09s/it]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import argparse\n",
    "\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('--b', type=str, default='NBA', help='board_name')\n",
    "#parser.add_argument('--ps', type=int, default='1', help='page_start')\n",
    "#parser.add_argument('--pe', type=int, default='2', help='page_end')\n",
    "#args = parser.parse_args()\n",
    "\n",
    "\n",
    "board_name = \n",
    "page_start = \n",
    "page_end = \n",
    "\n",
    "author, title, time, content, content_author, comment = [], [], [], [], [], []\n",
    "for n in tqdm(range(page_start,page_end,1)):\n",
    "    print(n)\n",
    "    res = requests.get(\"https://www.ptt.cc/bbs/\"+board_name+\"/index\"+str(n)+\".html\")\n",
    "    soup = BeautifulSoup(res.text)\n",
    "    for i in soup.select(\".title\"):\n",
    "        try:    \n",
    "            if i('a') == []:\n",
    "                continue\n",
    "            else:\n",
    "                res2 = requests.get(\"https://www.ptt.cc\"+i('a')[0]['href'])\n",
    "                soup2 = BeautifulSoup(res2.text)\n",
    "            \n",
    "                author_text = soup2.select(\".article-meta-value\")[0].text\n",
    "                title_text = soup2.select(\".article-meta-value\")[2].text\n",
    "                time_text = soup2.select(\".article-meta-value\")[3].text\n",
    "                content_text = soup2.select(\"#main-content\")[0].text.split(u\"※\")[0].split(time_text)[1]\n",
    "                \n",
    "                author.append(author_text)\n",
    "                title.append(title_text)\n",
    "                time.append(time_text)\n",
    "                content.append(content_text)         \n",
    "                lst = []\n",
    "                for m in soup2.select(\".push .f3.push-content\")[0:]:\n",
    "                    lst.append(m.text)\n",
    "                comment.append(lst)\n",
    "                lst_ = []\n",
    "                for z in soup2.select(\".push .f3.hl.push-userid\")[0:]:\n",
    "                    lst_.append(z.text.strip())\n",
    "                content_author.append(lst_)\n",
    "\n",
    "        except IndexError:\n",
    "            print(\"出錯喔\")\n",
    "\n",
    "\n",
    "assert len(author) == len(title) == len(time) == len(content)\n",
    "\n",
    "ptt = list(zip(title, time, author, content, content_author, comment))\n",
    "\n",
    "df = pd.DataFrame(ptt, columns=['標題', '時間', '作者', '內文', '留言作者','留言'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('{}_crawler.csv'.format(args.b), encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
