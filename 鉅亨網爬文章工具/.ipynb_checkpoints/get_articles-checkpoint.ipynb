{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 抓cnyes文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from datetime import date, datetime, time\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import urllib.parse as urlparse\n",
    "# import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = {}\n",
    "with open('categories.json', 'r') as f:\n",
    "    categories = json.load(f)\n",
    "\n",
    "categoryIds = [827, 838, 847, 852, 854, 839, 840, 841]\n",
    "baseUrl = 'https://news.cnyes.com/'\n",
    "baseApiUrl = 'https://news.cnyes.com/api/v3/news/category/'\n",
    "baseWebUrl = 'https://news.cnyes.com/news/id/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataFormat:\n",
    "      def __init__(self, newsId, categoryId, categoryName, title, author, article, timestamp):\n",
    "            self.newsId = newsId\n",
    "            self.categoryId = categoryId\n",
    "            self.categoryName = categoryName\n",
    "            self.title = title\n",
    "            self.author = author\n",
    "            self.article = article\n",
    "            self.timestamp = timestamp\n",
    "\n",
    "            def getData(self):\n",
    "                return {\n",
    "                  'newsId': self.newsId,\n",
    "                  'categoryId': self.categoryId,\n",
    "                  'categoryName': self.categoryName,\n",
    "                  'title': self.title,\n",
    "                  'author': self.author,\n",
    "                  'article': self.article,\n",
    "                  'timestamp': self.timestamp,\n",
    "                  'datetime': datetime.fromtimestamp(self.timestamp)\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticlesCollector:\n",
    "    def __init__(self, category_name, date_range):\n",
    "        '''\n",
    "        rl_category_name: tw_sotck/台股, future/期貨, fund/基金, fund/外匯, tw_insurance/保險, tw_housenews/房產\n",
    "        '''\n",
    "        self.__baseUrl = baseUrl\n",
    "        self.__baseApiUrl = baseApiUrl\n",
    "        self.__baseWebUrl = baseWebUrl\n",
    "        self.category_name = category_name\n",
    "        self.__responseDataList = []\n",
    "        self.__url_category_name = categories[self.category_name]['categoryName']\n",
    "        self.__filename = categories[self.category_name]['fileName']\n",
    "        self.__date_range = date_range\n",
    "        self.__startAt = int(datetime.combine(pd.to_datetime(date_range[0]), time.min).timestamp())\n",
    "        self.__endAt = int(datetime.combine(pd.to_datetime(date_range[1]), time.max).timestamp())\n",
    "        self.__limit = 30\n",
    "        self.__existing_df = None\n",
    "    \n",
    "    \n",
    "    def is_author(self, tag):\n",
    "        '''\n",
    "        判斷作者node\n",
    "        '''\n",
    "        return tag.has_attr('itemprop') and tag.get('itemprop') == 'author'\n",
    "  \n",
    "    def is_article(self, tag):\n",
    "        '''\n",
    "        判斷文章node\n",
    "        '''\n",
    "        return tag.has_attr('itemprop') and tag.get('itemprop') == 'articleBody'\n",
    "  \n",
    "    def store_to_csv(self):\n",
    "        '''\n",
    "        儲存結果為CSV檔\n",
    "        '''\n",
    "        columns = columns=['newsId', 'categoryId', 'categoryName', 'author', 'title', 'article', 'timestamp', 'datetime']\n",
    "        df = pd.DataFrame(self.__responseDataList, columns=columns)\n",
    "        try:\n",
    "            if (self.__existing_df is None):\n",
    "                df.to_csv(self.__filename, index=False, encoding='utf8')\n",
    "            else:\n",
    "                df_new = pd.concat([self.__existing_df, df])\n",
    "                df_new.drop_duplicates(subset=['newsId', 'categoryId'], inplace=True, keep='last')\n",
    "                df_new.to_csv(self.__filename, index=False, encoding='utf8')    \n",
    "            print('Updated to ' + self.__filename)\n",
    "            return df if self.__existing_df is None else df_new\n",
    "          except Exception as exc:\n",
    "            print(str(exc))\n",
    "            return exc\n",
    "  \n",
    "    def get_api_data(self, payload):\n",
    "        '''\n",
    "        依照文章類別取得文章列表資訊\n",
    "        '''\n",
    "        try:\n",
    "            r = requests.get(urlparse.urljoin(self.__baseApiUrl, self.__url_category_name), params=payload)\n",
    "            r.raise_for_status()\n",
    "            response = r.json()['items']\n",
    "            self.__last_page = response['last_page']\n",
    "            return response\n",
    "        except Exception as exc:\n",
    "            raise exc\n",
    "      \n",
    "    def response_handler(self, list_data, show_message):\n",
    "        '''\n",
    "        取得逐筆的文章\n",
    "        '''\n",
    "        if (list_data['categoryId'] not in categoryIds):\n",
    "            return None\n",
    "\n",
    "        if (show_message):\n",
    "            print('Fetching ' +  self.category_name + ' newsId:' + str(list_data['newsId']) + '... ', end='')\n",
    "\n",
    "        res = requests.get(urlparse.urljoin(baseWebUrl, str(list_data['newsId'])))\n",
    "\n",
    "        try:\n",
    "            res.raise_for_status()\n",
    "        except Exception as exc:\n",
    "            raise exc\n",
    "\n",
    "        soup = BeautifulSoup(res.text, 'lxml')\n",
    "        author = soup.find(self.is_author).span.string\n",
    "        article = ''.join([text.text for text in soup.find(self.is_article).select('p')])\n",
    "\n",
    "        if (show_message):\n",
    "              print('Done')\n",
    "  \n",
    "        return DataFormat(list_data['newsId'], list_data['categoryId'], self.category_name, list_data['title'], author, article, list_data['publishAt']).getData()\n",
    "  \n",
    "    def get_articles(self, show_message=True):      \n",
    "        '''\n",
    "        show_message: 是否顯示request過程\n",
    "        '''\n",
    "        payload = {\n",
    "          'startAt': self.__startAt,\n",
    "          'endAt': self.__endAt,\n",
    "          'limit': self.__limit,\n",
    "          'page': 0\n",
    "        }\n",
    "\n",
    "        err_msg = None\n",
    "\n",
    "        response = {}\n",
    "    \n",
    "        try:\n",
    "              self.__existing_df = pd.read_csv(self.__filename)\n",
    "        except Exception as exc:\n",
    "              print(str(exc))\n",
    "\n",
    "        while True:\n",
    "            if ('last_page' in response and payload['page'] == response['last_page']):\n",
    "                break\n",
    "            else:\n",
    "                try:\n",
    "                payload['page'] += 1\n",
    "                try:\n",
    "                response = self.get_api_data(payload)    \n",
    "                last_page = response['last_page']\n",
    "                if (response['last_page'] == 0):\n",
    "                    print('no available data between ' + self.__date_range[0] + ' ~ ' + self.__date_range[1])\n",
    "                break\n",
    "                except Exception as exc:\n",
    "                err_msg = str(exc)\n",
    "                    print(err_msg)\n",
    "                if (show_message):\n",
    "                    print(self.category_name + ' (' + str(payload['page']) + '/' + str(response['last_page']) + '):')\n",
    "                for data in response['data']:  \n",
    "                    try:\n",
    "                    rtn = self.response_handler(data, show_message)    \n",
    "                    if (rtn is not None):\n",
    "                    self.__responseDataList.append(rtn)\n",
    "                    except Exception as exc:\n",
    "                    err_msg = str(exc)\n",
    "                    print(err_msg)\n",
    "\n",
    "                if (len(self.__responseDataList)):\n",
    "                self.store_to_csv()\n",
    "            except Exception as exc:\n",
    "                err_msg = str(exc)\n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_range = ['2018-01-01', '2018-01-01']\n",
    "# get_articles(False): 不顯示log\n",
    "# ArticlesCollector('stock', date_range).get_articles()\n",
    "# ArticlesCollector('future', date_range).get_articles()\n",
    "# ArticlesCollector('forex', date_range).get_articles()\n",
    "# ArticlesCollector('house', date_range).get_articles()\n",
    "# ArticlesCollector('insurance', date_range).get_articles()\n",
    "# ArticlesCollector('fund', date_range).get_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
